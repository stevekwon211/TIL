> _TILì€ ì˜¤ëŠ˜ ê³µë¶€í•œ ê²ƒì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•œ ë‚´ìš©ë§Œ ì ìŠµë‹ˆë‹¤.
> ìì„¸í•œ ë‚´ìš©ì€ ì‹œë¦¬ì¦ˆë³„ë¡œ í¬ìŠ¤íŒ…í•©ë‹ˆë‹¤._

## ğŸ’»Data Science

**`[Kaggle Course - Intermediate Machine Learning]: Cross-Validation ì™„ë£Œ`**

Cross-Validation : ëª¨ë¸ì— ëŒ€í•œ ì—¬ëŸ¬ ì¸¡ì • ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ë‹¤ì–‘í•˜ê²Œ ë‚˜ë‰œ ë°ì´í„°ë“¤ë¡œ ëª¨ë¸ë§ì„ ì§„í–‰í•˜ëŠ” ê²ƒ

![image](https://user-images.githubusercontent.com/61633137/105024389-623e3800-5a8f-11eb-970c-cf7c2a73ab82.png)

ì˜ˆë¥¼ ë“¤ì–´ ë°ì´í„°ë¥¼ 5ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ë©° ê° ì¡°ê°ì€ ì „ì²´ ë°ì´í„°ì…‹ì˜ 20%ë¼ê³  í•œë‹¤. ì´ê²ƒì„ 5ê°œì˜ **`folds`**ë¼ê³  ë¶€ë¥¸ë‹¤.
Experiment 1ì—ì„œ 1st foldë¥¼ Validation setìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ 4ê°œì˜ foldëŠ” Training setìœ¼ë¡œ ì‚¬ìš©ëœë‹¤. ì´ê²ƒì„ ê³„ì† ë°˜ë³µí•´ì£¼ëŠ” ê²ƒ.

Cross-Validationì€ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ì¸¡ì •í•  ë•Œ ë§¤ìš° ìœ ìš©í•˜ê³  íŠ¹íˆ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ë§Œë“¤ì–´ì„œ ì„ íƒí•  ë•Œ ìœ ìš©í•˜ë‹¤.

Cross-Validationì„ ì´ìš©í•œ Tabular Playground Series - Jan 2021 ëª¨ë¸ ì½”ë“œ

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Read the data
df_train = pd.read_csv("train.csv", index_col='id')
df_test = pd.read_csv("test.csv", index_col='id')
submission = pd.read_csv("sample_submission.csv", index_col='id')
# Separate target from predictors
df_target = df_train.pop('target')

# Divide data into training and validation subsets
X_train, X_valid, y_train, y_valid = train_test_split(df_train, df_target, train_size=0.8, test_size=0.2, random_state=0)

# "Cardinality" means the number of unique values in a column
# Select categorical columns with relatively low cardinality (convenient but arbitary)
categorical_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == "object"]

# Select numerical columns
numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]

# Keep selected columns only
my_cols = categorical_cols + numerical_cols
X_train = X_train[my_cols].copy()
X_valid = X_valid[my_cols].copy()
```

```python
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder

# Preprocessing for numerical data
numerical_transformer = SimpleImputer(strategy='constant')

# Preprocessing for categorical data
'''
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])
'''

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        # ('cat', categorical_transformer, categorical_cols)
    ])
```

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

def get_score(n_estimators):
    my_pipeline = Pipeline(steps=[
        ('preprocessor', SimpleImputer()),
        ('model', RandomForestRegressor(n_estimators, random_state=0))
    ])
    scores = -1 * cross_val_score(my_pipeline, df_train, df_target,
                                  cv=3,
                                  scoring='neg_mean_absolute_error')
    rmse_scores = nq.sqrt(-scores)
    return rmse_scores.mean()
```

```python
results = {}
for i in range(1,9):
    results[50*i] = get_score(50*i)
```

```python
import matplotlib.pyplot as plt
%matplotlib inline

plt.plot(list(results.keys()), list(results.values()))
plt.show()
```

```python
from sklearn.metrics import mean_squared_error

n_estimators_best = 0

rf_model = RandomForestRegressor(n_estimators=n_estimators_best, random_state=0)
rf_model.fit(df_train, df_target)
submission['target'] = preds_test
submission.to_csv('Tabular_Jan2021_submission_2.csv')
```



<br>

***

## ğŸŒ Kaggle

**`Tabular Playground Series - Jan 2021 ì°¸ì—¬ì¤‘ `**
**`í˜„ì¬ ì ìˆ˜ : 0.70844`**
**`í˜„ì¬ ìˆœìœ„  722/1136`**

<br>

***

## â›“Algorithm

**`[solved.ac - Bronze V] : 2845, 2914, 3003 í’€ê¸°`**
![image](https://user-images.githubusercontent.com/61633137/105031066-19d74800-5a98-11eb-9c24-bb17dd8619f3.png)

ìš”ì¦˜ solved.acì—ì„œ ë¬¸ì œ í‘¸ëŠ”ê±°ì— ë§›ë“¤ë ¸ìŠµë‹ˆë‹¤ ã…‹ã…‹ã…‹ã…‹ ê²½í—˜ì¹˜ê°€ ì˜¬ë¼ê°€ë‹ˆ ë­”ê°€ ì˜¤ëœë§Œì— ê²Œì„í•˜ëŠ” ê¸°ë¶„ì´ë„ê¹Œ..
ë¸Œë¡ ì¦ˆ5ë¶€í„° ì°¨ê·¼ì°¨ê·¼ ëª¨ë“  ë¬¸ì œë¥¼ í’€ì–´ë´ì•¼ê² ìŠµë‹ˆë‹¤ğŸ˜

<br>

***

## ğŸ“Math

**`Loading...`**

<br>

***

## ğŸ‘¾J2KB

**`SSWEB ì£¼ìš” ê¸°ëŠ¥ ì—´ì‹¬íˆ ê°œë°œì¤‘...`**

<br>

***

## ğŸ‘¨â€ğŸ’»ì¼ìƒ

ì½”ë¡œë‚˜ ì„ ë³„ì§„ë£Œì†Œ ê·¼ë¬´ë¥¼ í•˜ë‹ˆ ë§ì´ í”¼ê³¤í•˜ë„¤ìš”.. ê·¸ë˜ë„ ì •ì‹ ë ¥ìœ¼ë¡œ ë²„í‹°ë©´ì„œ ê³µë¶€ë‘ ìƒí™œ íŒ¨í„´ ê³„ì† ì§€ì¼œë‚˜ê°€ì•¼ê² ìŠµë‹ˆë‹¤!! ğŸ’ª