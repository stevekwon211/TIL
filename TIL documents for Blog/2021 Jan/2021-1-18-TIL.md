> _TILì€ ì˜¤ëŠ˜ ê³µë¶€í•œ ê²ƒì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•œ ë‚´ìš©ë§Œ ì ìŠµë‹ˆë‹¤.
> ìì„¸í•œ ë‚´ìš©ì€ ì‹œë¦¬ì¦ˆë³„ë¡œ í¬ìŠ¤íŒ…í•©ë‹ˆë‹¤._

## ğŸ’»Data Science

**`[Coursera - Machine Learning by Andrew Ng 2ì£¼ì°¨]: Gradient Descent for Multiple Variables`**

**`[Kaggle Course - Intermediate Machine Learning]: Pipelines ì™„ë£Œ`**

Pipelines ê°•ì˜ ë“£ê³  ê°„ë‹¨í•˜ê²Œ ì§œë³¸ Tabular Playground Series Jan 2021 ì½”ë“œ

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Read the data
df_train = pd.read_csv("train.csv", index_col='id')
df_test = pd.read_csv("test.csv", index_col='id')
submission = pd.read_csv("sample_submission.csv", index_col='id')

# Separate target from predictors
df_target = df_train.pop('target')

# Divide data into training and validation subsets
X_train, X_valid, y_train, y_valid = train_test_split(df_train, df_target, train_size=0.8, test_size=0.2, random_state=0)

# "Cardinality" means the number of unique values in a column
# Select categorical columns with relatively low cardinality (convenient but arbitary)
categorical_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == "object"]

# Select numerical columns
numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]

# Keep selected columns only
my_cols = categorical_cols + numerical_cols
X_train = X_train[my_cols].copy()
X_valid = X_valid[my_cols].copy()
```

```python
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder

# Preprocessing for numerical data
numerical_transformer = SimpleImputer(strategy='constant')

# Preprocessing for categorical data
'''
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])
'''

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        # ('cat', categorical_transformer, categorical_cols)
    ])
```

```python
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators=100, random_state=0)
```

```python
from sklearn.metrics import mean_squared_error

# Bundle preprocessing and modeling code in a pipeline
my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                              ('model', model)
                             ])

# Preprocessing of training data, fit model 
my_pipeline.fit(X_train, y_train)

# Preprocessing of validation data, get predictions
preds = my_pipeline.predict(X_valid)

# Evaluate the model
def RMSE(y_valid, preds):
    return np.sqrt(mean_squared_error(y_valid, preds))
                   
print(RMSE(y_valid, preds))
```

```python
preds_test = my_pipeline.predict(df_test)
submission['target'] = preds_test
submission.to_csv('Tabular_Jan2021_submission.csv')
```

<br>

***

## ğŸŒ Kaggle

**`Tabular Playground Series - Jan 2021 ì°¸ì—¬ì¤‘ `**
**`í˜„ì¬ ì ìˆ˜ : 0.70862`**
**`í˜„ì¬ ìˆœìœ„  702/1103`**

<br>

***

## â›“Algorithm

**`[solved.ac - Bronze V] : 2558, 2920 í’€ê¸°`**

<br>

***

## ğŸ“Math

**`Loading...`**

<br>

***

## ğŸ‘¾J2KB

**`SSWEB ì£¼ìš” ê¸°ëŠ¥ ì—´ì‹¬íˆ ê°œë°œì¤‘...`**

<br>

***

## ğŸ‘¨â€ğŸ’»ì¼ìƒ

ì˜¤ëŠ˜ ë¡¯ë° ë°±í™”ì ì— í™•ì§„ìê°€ ë‚˜ì™€ì„œ ì „ì§ì›ì´ ì„ ë³„ì§„ë£Œì†Œì— ì™”ìŠµë‹ˆë‹¤..
ì‚¬ëŒ ë„ˆë¬´ ë§ì•„ì„œ ì •ì‹ ì—†ì—ˆë„¤ìš” ã…‹ã…‹ã…‹ã…‹ ğŸ˜±